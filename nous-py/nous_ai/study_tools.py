"""Study tools for generating educational content from notebook pages."""

import json
from typing import Literal

from pydantic import BaseModel, Field

from nous_ai.chat import chat
from nous_ai.models import ChatMessage, ProviderConfig


# ===== Study Guide Models =====


class KeyConcept(BaseModel):
    """A key concept with its definition."""

    term: str
    definition: str


class StudyGuideSection(BaseModel):
    """A section in the study guide."""

    heading: str
    content: str
    key_points: list[str] = Field(default_factory=list)


class PracticeQuestion(BaseModel):
    """A practice question with its answer."""

    question: str
    answer: str


class StudyGuide(BaseModel):
    """Structured study guide generated from content."""

    title: str
    learning_objectives: list[str] = Field(default_factory=list)
    key_concepts: list[KeyConcept] = Field(default_factory=list)
    sections: list[StudyGuideSection] = Field(default_factory=list)
    practice_questions: list[PracticeQuestion] = Field(default_factory=list)
    summary: str = ""


class StudyGuideOptions(BaseModel):
    """Options for study guide generation."""

    depth: Literal["brief", "standard", "comprehensive"] = "standard"
    focus_areas: list[str] = Field(default_factory=list)
    num_practice_questions: int = Field(default=5, ge=1, le=20)


# ===== FAQ Models =====


class FAQItem(BaseModel):
    """A single FAQ question and answer."""

    question: str
    answer: str
    source_page_id: str | None = None


class FAQ(BaseModel):
    """Collection of FAQ items."""

    questions: list[FAQItem] = Field(default_factory=list)


# ===== Flashcard Models =====


class GeneratedFlashcard(BaseModel):
    """A flashcard generated by AI."""

    front: str
    back: str
    card_type: Literal["basic", "cloze", "reversible"] = "basic"
    tags: list[str] = Field(default_factory=list)


class FlashcardGenerationResult(BaseModel):
    """Result of flashcard generation."""

    cards: list[GeneratedFlashcard] = Field(default_factory=list)
    source_page_ids: list[str] = Field(default_factory=list)


# ===== Briefing Document Models =====


class ActionItem(BaseModel):
    """An action item from the briefing."""

    description: str
    owner: str | None = None
    deadline: str | None = None
    priority: Literal["low", "medium", "high"] | None = None


class BriefingDocument(BaseModel):
    """Executive briefing document."""

    title: str
    executive_summary: str
    key_findings: list[str] = Field(default_factory=list)
    recommendations: list[str] = Field(default_factory=list)
    action_items: list[ActionItem] = Field(default_factory=list)
    detailed_sections: list[StudyGuideSection] = Field(default_factory=list)


# ===== Timeline Models =====


class TimelineEvent(BaseModel):
    """An event on the timeline."""

    id: str
    date: str  # ISO date string
    title: str
    description: str
    source_page_id: str
    category: str | None = None


class Timeline(BaseModel):
    """Timeline of events extracted from content."""

    events: list[TimelineEvent] = Field(default_factory=list)
    date_range_start: str | None = None
    date_range_end: str | None = None


# ===== Concept Map Models =====


class ConceptNode(BaseModel):
    """A node in the concept map."""

    id: str
    label: str
    node_type: Literal["concept", "example", "definition"] = "concept"
    description: str | None = None


class ConceptLink(BaseModel):
    """A link between concepts."""

    source: str  # node id
    target: str  # node id
    relationship: str  # "is-a", "has-a", "relates-to", etc.


class ConceptGraph(BaseModel):
    """Graph of concepts and their relationships."""

    nodes: list[ConceptNode] = Field(default_factory=list)
    links: list[ConceptLink] = Field(default_factory=list)


# ===== Page Input Models =====


class PageContent(BaseModel):
    """Content from a notebook page."""

    page_id: str
    title: str
    content: str
    tags: list[str] = Field(default_factory=list)


# ===== Generation Functions =====


def generate_study_guide(
    pages: list[PageContent],
    config: ProviderConfig,
    options: StudyGuideOptions | None = None,
) -> StudyGuide:
    """Generate a structured study guide from notebook pages.

    Args:
        pages: List of page contents to generate study guide from
        config: AI provider configuration
        options: Optional generation options

    Returns:
        StudyGuide: Structured study guide with objectives, concepts, sections, and questions
    """
    if options is None:
        options = StudyGuideOptions()

    # Combine page contents
    combined_content = "\n\n".join(
        f"# {page.title}\n{page.content}" for page in pages
    )

    depth_instructions = {
        "brief": "Create a brief overview with key points only.",
        "standard": "Create a balanced study guide with moderate detail.",
        "comprehensive": "Create a comprehensive study guide with thorough explanations.",
    }

    focus_instruction = ""
    if options.focus_areas:
        focus_instruction = f"\nFocus particularly on these areas: {', '.join(options.focus_areas)}"

    system_prompt = f"""You are an expert educational content creator. Generate a structured study guide from the provided content.

{depth_instructions[options.depth]}{focus_instruction}

You MUST respond with valid JSON matching this exact structure:
{{
  "title": "string - descriptive title for the study guide",
  "learning_objectives": ["array of specific learning objectives"],
  "key_concepts": [
    {{"term": "concept name", "definition": "clear definition"}}
  ],
  "sections": [
    {{
      "heading": "section heading",
      "content": "detailed explanation",
      "key_points": ["important points from this section"]
    }}
  ],
  "practice_questions": [
    {{"question": "practice question", "answer": "detailed answer"}}
  ],
  "summary": "string - concise summary of the entire content"
}}

Generate exactly {options.num_practice_questions} practice questions.
Only output the JSON, no additional text."""

    messages = [
        ChatMessage(role="system", content=system_prompt),
        ChatMessage(role="user", content=f"Generate a study guide from this content:\n\n{combined_content}"),
    ]

    response = chat(messages, config)

    # Parse JSON response
    content = response.content.strip()
    # Handle potential markdown code blocks
    if content.startswith("```"):
        lines = content.split("\n")
        content = "\n".join(lines[1:-1] if lines[-1] == "```" else lines[1:])

    data = json.loads(content)
    return StudyGuide(**data)


def generate_study_guide_sync(
    pages: list[PageContent],
    config: ProviderConfig,
    options: StudyGuideOptions | None = None,
) -> StudyGuide:
    """Synchronous version of generate_study_guide."""
    return generate_study_guide(pages, config, options)


def generate_faq(
    pages: list[PageContent],
    config: ProviderConfig,
    num_questions: int = 10,
) -> FAQ:
    """Generate FAQ from notebook pages.

    Args:
        pages: List of page contents
        config: AI provider configuration
        num_questions: Number of FAQ items to generate

    Returns:
        FAQ: Collection of generated questions and answers
    """
    # Combine page contents with IDs for source tracking
    combined_content = "\n\n".join(
        f"[PAGE_ID: {page.page_id}]\n# {page.title}\n{page.content}"
        for page in pages
    )

    system_prompt = f"""You are an expert at extracting important questions and answers from educational content.

Generate {num_questions} frequently asked questions (FAQs) based on the content.
Each question should address a key concept or common confusion point.
Include the source page ID where the answer was found.

You MUST respond with valid JSON matching this exact structure:
{{
  "questions": [
    {{
      "question": "clear, well-formed question",
      "answer": "comprehensive answer",
      "source_page_id": "the PAGE_ID where this information was found (or null)"
    }}
  ]
}}

Only output the JSON, no additional text."""

    messages = [
        ChatMessage(role="system", content=system_prompt),
        ChatMessage(role="user", content=f"Generate FAQ from this content:\n\n{combined_content}"),
    ]

    response = chat(messages, config)

    content = response.content.strip()
    if content.startswith("```"):
        lines = content.split("\n")
        content = "\n".join(lines[1:-1] if lines[-1] == "```" else lines[1:])

    data = json.loads(content)
    return FAQ(**data)


def generate_faq_sync(
    pages: list[PageContent],
    config: ProviderConfig,
    num_questions: int = 10,
) -> FAQ:
    """Synchronous version of generate_faq."""
    return generate_faq(pages, config, num_questions)


def generate_flashcards(
    pages: list[PageContent],
    config: ProviderConfig,
    num_cards: int = 20,
    card_types: list[Literal["basic", "cloze", "reversible"]] | None = None,
) -> FlashcardGenerationResult:
    """Generate flashcards from notebook pages.

    Args:
        pages: List of page contents
        config: AI provider configuration
        num_cards: Target number of flashcards to generate
        card_types: Types of cards to generate (default: basic only)

    Returns:
        FlashcardGenerationResult: Generated flashcards with source page IDs
    """
    if card_types is None:
        card_types = ["basic"]

    combined_content = "\n\n".join(
        f"# {page.title}\n{page.content}" for page in pages
    )

    card_type_instructions = []
    if "basic" in card_types:
        card_type_instructions.append('- "basic": Simple front/back question-answer cards')
    if "cloze" in card_types:
        card_type_instructions.append('- "cloze": Fill-in-the-blank style with {{c1::hidden text}} format')
    if "reversible" in card_types:
        card_type_instructions.append('- "reversible": Cards that work both ways (e.g., term<->definition)')

    card_type_text = "\n".join(card_type_instructions)

    system_prompt = f"""You are an expert at creating effective spaced repetition flashcards.

Generate {num_cards} high-quality flashcards from the provided content.

Card types to use:
{card_type_text}

Guidelines:
- Each card should test ONE concept
- Questions should be clear and unambiguous
- Answers should be concise but complete
- For cloze cards, use {{{{c1::text}}}} format for deletions
- Include relevant tags based on the topic

You MUST respond with valid JSON matching this exact structure:
{{
  "cards": [
    {{
      "front": "question or prompt",
      "back": "answer",
      "card_type": "basic|cloze|reversible",
      "tags": ["relevant", "tags"]
    }}
  ]
}}

Only output the JSON, no additional text."""

    messages = [
        ChatMessage(role="system", content=system_prompt),
        ChatMessage(role="user", content=f"Generate flashcards from this content:\n\n{combined_content}"),
    ]

    response = chat(messages, config)

    content = response.content.strip()
    if content.startswith("```"):
        lines = content.split("\n")
        content = "\n".join(lines[1:-1] if lines[-1] == "```" else lines[1:])

    data = json.loads(content)
    return FlashcardGenerationResult(
        cards=[GeneratedFlashcard(**card) for card in data["cards"]],
        source_page_ids=[page.page_id for page in pages],
    )


def generate_flashcards_sync(
    pages: list[PageContent],
    config: ProviderConfig,
    num_cards: int = 20,
    card_types: list[Literal["basic", "cloze", "reversible"]] | None = None,
) -> FlashcardGenerationResult:
    """Synchronous version of generate_flashcards."""
    return generate_flashcards(pages, config, num_cards, card_types)


def generate_briefing(
    pages: list[PageContent],
    config: ProviderConfig,
    include_action_items: bool = True,
) -> BriefingDocument:
    """Generate an executive briefing document from notebook pages.

    Args:
        pages: List of page contents
        config: AI provider configuration
        include_action_items: Whether to extract action items

    Returns:
        BriefingDocument: Executive briefing with summary, findings, and recommendations
    """
    combined_content = "\n\n".join(
        f"# {page.title}\n{page.content}" for page in pages
    )

    action_items_instruction = ""
    if include_action_items:
        action_items_instruction = """
  "action_items": [
    {
      "description": "what needs to be done",
      "owner": "who should do it (or null)",
      "deadline": "when it's due (or null)",
      "priority": "low|medium|high (or null)"
    }
  ],"""

    system_prompt = f"""You are an expert at synthesizing information into executive briefings.

Generate a concise executive briefing from the provided content.

You MUST respond with valid JSON matching this exact structure:
{{
  "title": "descriptive title for the briefing",
  "executive_summary": "one paragraph overview (2-4 sentences)",
  "key_findings": ["array of key findings as bullet points"],
  "recommendations": ["array of actionable recommendations"],{action_items_instruction}
  "detailed_sections": [
    {{
      "heading": "section heading",
      "content": "detailed content",
      "key_points": ["important points"]
    }}
  ]
}}

Keep the executive summary concise. Key findings should be 3-7 points.
Only output the JSON, no additional text."""

    messages = [
        ChatMessage(role="system", content=system_prompt),
        ChatMessage(role="user", content=f"Generate a briefing from this content:\n\n{combined_content}"),
    ]

    response = chat(messages, config)

    content = response.content.strip()
    if content.startswith("```"):
        lines = content.split("\n")
        content = "\n".join(lines[1:-1] if lines[-1] == "```" else lines[1:])

    data = json.loads(content)
    return BriefingDocument(**data)


def generate_briefing_sync(
    pages: list[PageContent],
    config: ProviderConfig,
    include_action_items: bool = True,
) -> BriefingDocument:
    """Synchronous version of generate_briefing."""
    return generate_briefing(pages, config, include_action_items)


def extract_timeline(
    pages: list[PageContent],
    config: ProviderConfig,
) -> Timeline:
    """Extract a timeline of events from notebook pages.

    Args:
        pages: List of page contents
        config: AI provider configuration

    Returns:
        Timeline: Chronological events with dates and descriptions
    """
    combined_content = "\n\n".join(
        f"[PAGE_ID: {page.page_id}]\n# {page.title}\n{page.content}"
        for page in pages
    )

    system_prompt = """You are an expert at extracting chronological information from text.

Identify all events with dates or time references in the content.
Extract them into a timeline format.

You MUST respond with valid JSON matching this exact structure:
{
  "events": [
    {
      "id": "unique_id_1",
      "date": "YYYY-MM-DD or YYYY-MM or YYYY format",
      "title": "brief event title",
      "description": "what happened",
      "source_page_id": "the PAGE_ID where this was found",
      "category": "optional category like 'milestone', 'deadline', 'meeting', etc."
    }
  ],
  "date_range_start": "earliest date (YYYY-MM-DD) or null",
  "date_range_end": "latest date (YYYY-MM-DD) or null"
}

Sort events chronologically. Use ISO date format where possible.
If only month/year is known, use YYYY-MM-01. If only year, use YYYY-01-01.
Only output the JSON, no additional text."""

    messages = [
        ChatMessage(role="system", content=system_prompt),
        ChatMessage(role="user", content=f"Extract timeline events from this content:\n\n{combined_content}"),
    ]

    response = chat(messages, config)

    content = response.content.strip()
    if content.startswith("```"):
        lines = content.split("\n")
        content = "\n".join(lines[1:-1] if lines[-1] == "```" else lines[1:])

    data = json.loads(content)
    return Timeline(**data)


def extract_timeline_sync(
    pages: list[PageContent],
    config: ProviderConfig,
) -> Timeline:
    """Synchronous version of extract_timeline."""
    return extract_timeline(pages, config)


def extract_concepts(
    pages: list[PageContent],
    config: ProviderConfig,
    max_nodes: int = 30,
) -> ConceptGraph:
    """Extract concepts and their relationships from notebook pages.

    Args:
        pages: List of page contents
        config: AI provider configuration
        max_nodes: Maximum number of concept nodes

    Returns:
        ConceptGraph: Graph of concepts and their relationships
    """
    combined_content = "\n\n".join(
        f"# {page.title}\n{page.content}" for page in pages
    )

    system_prompt = f"""You are an expert at identifying concepts and their relationships in text.

Extract key concepts and how they relate to each other.
Create a concept map with nodes and links.

You MUST respond with valid JSON matching this exact structure:
{{
  "nodes": [
    {{
      "id": "unique_node_id",
      "label": "concept name",
      "node_type": "concept|example|definition",
      "description": "brief description (optional)"
    }}
  ],
  "links": [
    {{
      "source": "source_node_id",
      "target": "target_node_id",
      "relationship": "is-a|has-a|relates-to|causes|requires|etc."
    }}
  ]
}}

Guidelines:
- Limit to {max_nodes} most important nodes
- Use meaningful relationship labels
- node_type should be:
  - "concept" for abstract ideas or main topics
  - "example" for specific instances or cases
  - "definition" for terminology or definitions
- Ensure all link source/target IDs exist in nodes
Only output the JSON, no additional text."""

    messages = [
        ChatMessage(role="system", content=system_prompt),
        ChatMessage(role="user", content=f"Extract concept map from this content:\n\n{combined_content}"),
    ]

    response = chat(messages, config)

    content = response.content.strip()
    if content.startswith("```"):
        lines = content.split("\n")
        content = "\n".join(lines[1:-1] if lines[-1] == "```" else lines[1:])

    data = json.loads(content)
    return ConceptGraph(**data)


def extract_concepts_sync(
    pages: list[PageContent],
    config: ProviderConfig,
    max_nodes: int = 30,
) -> ConceptGraph:
    """Synchronous version of extract_concepts."""
    return extract_concepts(pages, config, max_nodes)


# ===== Source-Cited Chat Models =====


class RAGChunk(BaseModel):
    """A chunk from RAG retrieval with source information."""

    chunk_id: str
    page_id: str
    notebook_id: str
    title: str  # page title
    content: str
    score: float


class Citation(BaseModel):
    """A citation reference in the response."""

    id: int  # Citation number [1], [2], etc.
    page_id: str
    page_title: str
    excerpt: str  # Relevant excerpt from the source
    relevance_score: float


class CitedResponse(BaseModel):
    """Response with inline citations."""

    content: str  # Response with inline citations like [1], [2]
    citations: list[Citation] = Field(default_factory=list)


# ===== Source-Cited Chat Functions =====


def chat_with_citations(
    query: str,
    context_chunks: list[RAGChunk],
    config: ProviderConfig,
    max_citations: int = 5,
) -> CitedResponse:
    """Chat with RAG context and return response with source citations.

    The AI will respond to the query using the provided context chunks
    and include inline citations [1], [2], etc. that reference the sources.

    Args:
        query: The user's question
        context_chunks: RAG chunks with source information
        config: AI provider configuration
        max_citations: Maximum number of citations to include

    Returns:
        CitedResponse with content containing inline citations and citation list
    """
    # Build context with numbered sources
    context_parts = []
    for i, chunk in enumerate(context_chunks[:max_citations], 1):
        context_parts.append(
            f"[Source {i}] (Page: {chunk.title})\n{chunk.content}"
        )

    context_text = "\n\n".join(context_parts)

    system_prompt = f"""You are a helpful assistant that answers questions based on provided sources.

You MUST cite your sources using inline citations like [1], [2], etc.
Each citation number corresponds to the source number in the context.
Only cite sources that you actually use in your answer.

IMPORTANT:
- Use [1], [2], etc. inline in your response where you use information from that source
- Be accurate and only include information from the provided sources
- If the sources don't contain enough information to fully answer, say so

Available sources:
{context_text}

Respond with a JSON object:
{{
  "content": "Your answer with inline citations like [1] or [2]",
  "citations": [
    {{
      "id": 1,
      "page_id": "source page id",
      "page_title": "source page title",
      "excerpt": "relevant quote from the source (max 100 chars)",
      "relevance_score": 0.95
    }}
  ]
}}

Only include citations for sources you actually referenced in your answer.
Only output the JSON, no additional text."""

    messages = [
        ChatMessage(role="system", content=system_prompt),
        ChatMessage(role="user", content=query),
    ]

    response = chat(messages, config)

    content = response.content.strip()
    if content.startswith("```"):
        lines = content.split("\n")
        content = "\n".join(lines[1:-1] if lines[-1] == "```" else lines[1:])

    try:
        data = json.loads(content)
        # Map citation page_ids from the context chunks
        citations = []
        for cit in data.get("citations", []):
            cit_id = cit.get("id", 0)
            if 1 <= cit_id <= len(context_chunks):
                chunk = context_chunks[cit_id - 1]
                citations.append(Citation(
                    id=cit_id,
                    page_id=chunk.page_id,
                    page_title=chunk.title,
                    excerpt=cit.get("excerpt", chunk.content[:100]),
                    relevance_score=cit.get("relevance_score", chunk.score),
                ))
        return CitedResponse(
            content=data.get("content", ""),
            citations=citations,
        )
    except json.JSONDecodeError:
        # Fallback: return content without structured citations
        return CitedResponse(content=response.content)


def chat_with_citations_sync(
    query: str,
    context_chunks: list[RAGChunk],
    config: ProviderConfig,
    max_citations: int = 5,
) -> CitedResponse:
    """Synchronous version of chat_with_citations."""
    return chat_with_citations(query, context_chunks, config, max_citations)
